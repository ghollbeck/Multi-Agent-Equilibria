{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized LLM-driven Decision Making for Iterated Prisoner's Dilemma\n",
    "\n",
    "\n",
    "\n",
    "This notebook implements an LLM-driven simulation of the Iterated Prisoner's Dilemma using OpenAI's API. \n",
    "\n",
    "The simulation features:\n",
    "\n",
    "- Dynamic strategy generation using GPT-4\n",
    "\n",
    "- Evolutionary agent selection\n",
    "\n",
    "- Asynchronous execution for improved performance\n",
    "\n",
    "- Detailed logging and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, we'll import the necessary libraries and set up our OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from typing import List, Tuple, Dict\n",
    "import aiohttp\n",
    "\n",
    "# Load environment variables and setup OpenAI client\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "async_client = AsyncOpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Implementation\n",
    "\n",
    "The EnhancedAgent class represents a player in the Prisoner's Dilemma game.\n",
    "\n",
    "Each agent:\n",
    "\n",
    "- Has a unique strategy matrix generated by GPT-4\n",
    "\n",
    "- Maintains a history of interactions\n",
    "\n",
    "- Makes decisions based on past interactions and current game state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "class EnhancedAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.total_score = 0\n",
    "        self.history = []  # Log of (opponent, own_action, opp_action, own_payoff)\n",
    "        self.strategy_matrix = None  # Will be set asynchronously\n",
    "\n",
    "    async def initialize(self):\n",
    "        \"\"\"Asynchronously initialize the agent's strategy matrix\"\"\"\n",
    "        self.strategy_matrix = await self.generate_strategy_matrix()\n",
    "        return self\n",
    "\n",
    "    async def generate_strategy_matrix(self):\n",
    "        prompt = \"\"\"\n",
    "You are defining a strategy for repeatedly playing the Iterated Prisoner's Dilemma.\n",
    "Output a concise strategy matrix that clearly states your action (C or D) based on:\n",
    "1. Your previous action\n",
    "2. Your opponent's previous action\n",
    "Format example:\n",
    "CC: C\n",
    "CD: D\n",
    "DC: C\n",
    "DD: D\n",
    "\n",
    "Additionally, provide one brief sentence describing your overall reasoning.\n",
    "Do NOT reference any classic strategies by name.\n",
    "\"\"\"\n",
    "        response = await async_client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.9,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    async def decide_action(self, opponent_name):\n",
    "        history_summary = \"\\n\".join(\n",
    "            [f\"Round {idx+1}: Opponent: {opp}, You: {self_act}, Opponent action: {opp_act}, Your payoff: {payoff}\"\n",
    "             for idx, (opp, self_act, opp_act, payoff) in enumerate(self.history[-3:])]\n",
    "        ) or \"No previous rounds.\"\n",
    "\n",
    "        decision_prompt = f\"\"\"\n",
    "You are playing the Iterated Prisoner's Dilemma against '{opponent_name}'.\n",
    "Your strategy matrix is:\n",
    "{self.strategy_matrix}\n",
    "\n",
    "Recent interaction history:\n",
    "{history_summary}\n",
    "\n",
    "Based on this information, decide your next action. \n",
    "Respond with a single character (C or D) and a brief explanatory sentence.\n",
    "\"\"\"\n",
    "        response = await async_client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": decision_prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=20\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        action = content[0].upper() if content and content[0].upper() in ['C', 'D'] else random.choice(['C', 'D'])\n",
    "        reasoning = content[2:].strip() if len(content) > 2 else \"No clear reasoning provided.\"\n",
    "        return action, reasoning\n",
    "\n",
    "    def log_interaction(self, opponent, own_action, opp_action, payoff):\n",
    "        self.history.append((opponent, own_action, opp_action, payoff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Configuration\n",
    "\n",
    "Define the payoff matrix for the Prisoner's Dilemma and helper functions for agent creation and interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Define the standard Prisoner's Dilemma payoff matrix.\n",
    "payoff_matrix = {\n",
    "    ('C', 'C'): (3, 3),  # Both cooperate\n",
    "    ('C', 'D'): (0, 5),  # Player 1 cooperates, Player 2 defects\n",
    "    ('D', 'C'): (5, 0),  # Player 1 defects, Player 2 cooperates\n",
    "    ('D', 'D'): (1, 1),  # Both defect\n",
    "}\n",
    "\n",
    "async def create_enhanced_agents(n=4) -> List[EnhancedAgent]:\n",
    "    \"\"\"Create and initialize multiple agents concurrently\"\"\"\n",
    "    agents = [EnhancedAgent(f\"Agent_{i}\") for i in range(n)]\n",
    "    # Initialize all agents concurrently\n",
    "    agents = await asyncio.gather(*(agent.initialize() for agent in agents))\n",
    "    return agents\n",
    "\n",
    "async def simulate_interaction(agent_a: EnhancedAgent, agent_b: EnhancedAgent) -> Dict:\n",
    "    \"\"\"Simulate an interaction between two agents asynchronously\"\"\"\n",
    "    # Get actions concurrently\n",
    "    (action_a, reasoning_a), (action_b, reasoning_b) = await asyncio.gather(\n",
    "        agent_a.decide_action(agent_b.name),\n",
    "        agent_b.decide_action(agent_a.name)\n",
    "    )\n",
    "    \n",
    "    payoff_a, payoff_b = payoff_matrix[(action_a, action_b)]\n",
    "    agent_a.total_score += payoff_a\n",
    "    agent_b.total_score += payoff_b\n",
    "    agent_a.log_interaction(agent_b.name, action_a, action_b, payoff_a)\n",
    "    agent_b.log_interaction(agent_a.name, action_b, action_a, payoff_b)\n",
    "\n",
    "    return {\n",
    "        \"Pair\": f\"{agent_a.name}-{agent_b.name}\",\n",
    "        \"Actions\": f\"{action_a}-{action_b}\",\n",
    "        \"Payoffs\": f\"{payoff_a}-{payoff_b}\",\n",
    "        \"Strategy_A\": agent_a.strategy_matrix,\n",
    "        \"Strategy_B\": agent_b.strategy_matrix,\n",
    "        \"Reasoning_A\": reasoning_a,\n",
    "        \"Reasoning_B\": reasoning_b,\n",
    "        \"Score_A\": agent_a.total_score,\n",
    "        \"Score_B\": agent_b.total_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Simulation\n",
    "\n",
    "The main simulation function runs multiple generations of agents, with each generation involving:\n",
    "\n",
    "1. Concurrent agent interactions\n",
    "\n",
    "2. Logging of results\n",
    "\n",
    "3. Evolution (selection of top performers)\n",
    "\n",
    "4. Creation of new agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "async def run_llm_driven_simulation(num_agents=4, num_generations=5):\n",
    "    # Create timestamped results folder in current working directory\n",
    "    results_folder = os.path.join(os.getcwd(), \"simulation_results\")\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_folder = os.path.join(results_folder, f\"run_{current_time}\")\n",
    "    os.makedirs(run_folder, exist_ok=True)\n",
    "    \n",
    "    agents = await create_enhanced_agents(num_agents)\n",
    "    all_detailed_logs = []\n",
    "    generation_summary = []\n",
    "    \n",
    "    for gen in range(num_generations):\n",
    "        print(f\"\\n=== Generation {gen+1} ===\")\n",
    "        detailed_logs = []\n",
    "        random.shuffle(agents)\n",
    "        \n",
    "        # Rest of your existing function code remains the same\n",
    "\n",
    "        # Pair agents and simulate interactions concurrently\n",
    "        interaction_tasks = []\n",
    "        for i in range(0, len(agents), 2):\n",
    "            if i + 1 < len(agents):\n",
    "                interaction_tasks.append(simulate_interaction(agents[i], agents[i+1]))\n",
    "        \n",
    "        # Wait for all interactions to complete\n",
    "        interaction_results = await asyncio.gather(*interaction_tasks)\n",
    "        \n",
    "        # Process results\n",
    "        for result in interaction_results:\n",
    "            detailed_logs.append({\n",
    "                \"Generation\": gen+1,\n",
    "                **result\n",
    "            })\n",
    "            print(f\"{result['Pair']}: {result['Actions']}, Payoffs: {result['Payoffs']}\")\n",
    "\n",
    "        all_detailed_logs.extend(detailed_logs)\n",
    "\n",
    "        # Log generation summary\n",
    "        avg_score = sum(a.total_score for a in agents) / len(agents)\n",
    "        generation_summary.append({\n",
    "            \"Generation\": gen+1,\n",
    "            \"Average_Score\": avg_score,\n",
    "            \"Strategies\": [a.strategy_matrix for a in agents],\n",
    "            \"Total_Scores\": [a.total_score for a in agents]\n",
    "        })\n",
    "\n",
    "        # Evolution: select top agents and generate new ones.\n",
    "        agents.sort(key=lambda a: a.total_score, reverse=True)\n",
    "        top_agents = agents[:num_agents // 2]\n",
    "        new_agents = await create_enhanced_agents(num_agents // 2)\n",
    "        agents = top_agents + new_agents\n",
    "\n",
    "        # Reset scores for next generation\n",
    "        for agent in agents:\n",
    "            agent.total_score = 0\n",
    "\n",
    "    # Save run parameters\n",
    "    params = {\n",
    "        \"num_agents\": num_agents,\n",
    "        \"num_generations\": num_generations,\n",
    "        \"payoff_matrix\": {\n",
    "            \"CC\": payoff_matrix[('C', 'C')],\n",
    "            \"CD\": payoff_matrix[('C', 'D')],\n",
    "            \"DC\": payoff_matrix[('D', 'C')],\n",
    "            \"DD\": payoff_matrix[('D', 'D')]\n",
    "        },\n",
    "        \"timestamp\": current_time\n",
    "    }\n",
    "    with open(os.path.join(run_folder, \"parameters.json\"), 'w') as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "\n",
    "    # Save detailed logs\n",
    "    detailed_df = pd.DataFrame(all_detailed_logs)\n",
    "    detailed_df.to_csv(os.path.join(run_folder, \"detailed_logs.csv\"), index=False)\n",
    "    detailed_df.to_json(os.path.join(run_folder, \"detailed_logs.json\"), orient=\"records\", indent=4)\n",
    "\n",
    "    # Save generation summary\n",
    "    summary_df = pd.DataFrame(generation_summary)\n",
    "    summary_df.to_csv(os.path.join(run_folder, \"generation_summary.csv\"), index=False)\n",
    "    summary_df.to_json(os.path.join(run_folder, \"generation_summary.json\"), orient=\"records\", indent=4)\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    generations = range(1, num_generations + 1)\n",
    "    avg_scores = [entry[\"Average_Score\"] for entry in generation_summary]\n",
    "    plt.plot(generations, avg_scores, marker='o', linestyle='-', linewidth=2, color='blue')\n",
    "    plt.title(\"Average Cooperation Score over Generations\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Average Score\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(run_folder, \"cooperation_over_generations.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\nSimulation completed. Results saved in: {run_folder}\")\n",
    "    return generation_summary, all_detailed_logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Simulation\n",
    "\n",
    "Execute the simulation with specified parameters.\n",
    "\n",
    "Note: This will make multiple API calls to OpenAI's GPT-4, so ensure your API key is set up correctly.\n",
    "\n",
    "\n",
    "\n",
    "To run in a Jupyter notebook, first install nest_asyncio:\n",
    "\n",
    "```bash\n",
    "\n",
    "pip install nest_asyncio\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Then run the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Helper function to run async code in Jupyter\n",
    "async def run_simulation():\n",
    "    return await run_llm_driven_simulation(num_agents=6, num_generations=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generation 1 ===\n",
      "Agent_0-Agent_4: C-C, Payoffs: 3-3\n",
      "Agent_1-Agent_3: C-C, Payoffs: 3-3\n",
      "Agent_5-Agent_2: C-C, Payoffs: 3-3\n",
      "\n",
      "=== Generation 2 ===\n",
      "Agent_2-Agent_1: C-C, Payoffs: 3-3\n",
      "Agent_4-Agent_0: C-C, Payoffs: 3-3\n",
      "Agent_1-Agent_0: C-C, Payoffs: 3-3\n",
      "\n",
      "=== Generation 3 ===\n",
      "Agent_2-Agent_2: C-C, Payoffs: 3-3\n",
      "Agent_1-Agent_1: C-C, Payoffs: 3-3\n",
      "Agent_0-Agent_4: C-C, Payoffs: 3-3\n",
      "\n",
      "Simulation completed. Results saved in: /Users/gaborhollbeck/Desktop/GitHub/32_Stanford_Research/Multi-Agent-Equilibria/Games/simulation_results/run_2025-03-16_15-56-02\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# Setup for Jupyter notebook execution\n",
    "if not os.getenv('JUPYTER_RUNNING_IN_SCRIPT'):\n",
    "    try:\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        import asyncio\n",
    "        # Create event loop and run simulation\n",
    "        loop = asyncio.get_event_loop()\n",
    "        summary, logs = loop.run_until_complete(run_simulation())\n",
    "    except ImportError:\n",
    "        print(\"Please install nest_asyncio: pip install nest_asyncio\")\n",
    "else:\n",
    "    # For running as a script\n",
    "    summary, logs = asyncio.run(run_llm_driven_simulation(num_agents=6, num_generations=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization\n",
    "\n",
    "After running the simulation, you can analyze the results using the returned data:\n",
    "\n",
    "- `summary`: Contains generation-level statistics\n",
    "\n",
    "- `logs`: Contains detailed interaction logs\n",
    "\n",
    "\n",
    "\n",
    "Example analysis:\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrames for analysis\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "logs_df = pd.DataFrame(logs)\n",
    "\n",
    "\n",
    "\n",
    "# Analyze cooperation rates\n",
    "\n",
    "cooperation_rates = logs_df['Actions'].apply(lambda x: x.count('C') / len(x))\n",
    "\n",
    "print(f\"Average cooperation rate: {cooperation_rates.mean():.2%}\")\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
